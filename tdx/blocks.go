package tdx

import (
	"bufio"
	"encoding/csv"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"regexp"
	"sort"
	"strings"
	"time"

	"github.com/jing2uo/tdx2db/model"
	"github.com/jing2uo/tdx2db/utils"
	"golang.org/x/text/encoding/simplifiedchinese"
	"golang.org/x/text/transform"
)

// ExportResult å¯¼å‡ºç»“æžœï¼ŒåŒ…å«æ‰€æœ‰ç”Ÿæˆçš„CSVæ–‡ä»¶è·¯å¾„
type ExportResult struct {
	StockInfoFile            string
	HolidaysFile             string
	BlockMembersConceptFile  string
	BlockMembersIndustryFile string
	BlockInfoFile            string
}

func ExportTdxBlocksDataToCSV(tdxHome, outputDir string) (*ExportResult, error) {
	// å±•å¼€è·¯å¾„ï¼ˆå¦‚æžœæœ‰ ~ ç­‰ç¬¦å·ï¼‰
	tdxHome = expandPath(tdxHome)
	outputDir = expandPath(outputDir)

	// 1. æ£€æŸ¥å¹¶åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆè¿™æ˜¯å¿…é¡»çš„ï¼Œå¦‚æžœå¤±è´¥åˆ™è¿”å›žé”™è¯¯ï¼‰
	if err := utils.CheckOutputDir(outputDir); err != nil {
		return nil, fmt.Errorf("è¾“å‡ºç›®å½•æ£€æŸ¥å¤±è´¥: %w", err)
	}

	// 2. æ£€æŸ¥ hq_cache ç›®å½•ï¼ˆè¿™æ˜¯å¿…é¡»çš„ï¼Œå¦‚æžœå¤±è´¥åˆ™è¿”å›žé”™è¯¯ï¼‰
	hqCache := filepath.Join(tdxHome, "T0002/hq_cache")
	if err := utils.CheckDirectory(hqCache); err != nil {
		return nil, fmt.Errorf("é€šè¾¾ä¿¡å®‰è£…ç›®å½•æ£€æŸ¥å¤±è´¥: %w", err)
	}

	// 3. å®šä¹‰æ‰€æœ‰è¾“å…¥æ–‡ä»¶
	inputFiles := map[string]string{
		"è‚¡ç¥¨ä¿¡æ¯æ–‡ä»¶": filepath.Join(hqCache, "infoharbor_ex.code"),
		"å‡æœŸæ—¥åŽ†æ–‡ä»¶": filepath.Join(hqCache, "needini.dat"),
		"æ¦‚å¿µæ¿å—æ–‡ä»¶": filepath.Join(hqCache, "infoharbor_block.dat"),
		"è¡Œä¸šæ•°æ®æ–‡ä»¶": filepath.Join(hqCache, "tdxhy.cfg"),
		"æ¿å—ä¿¡æ¯æ–‡ä»¶": filepath.Join(hqCache, "tdxzs3.cfg"),
	}

	// 4. æ£€æŸ¥æ‰€æœ‰è¾“å…¥æ–‡ä»¶ï¼Œè®°å½•å“ªäº›æ–‡ä»¶å¯ç”¨
	fileAvailable := make(map[string]bool)
	for name, path := range inputFiles {
		if err := utils.CheckFile(path); err != nil {
			fmt.Printf("ðŸš¨ è­¦å‘Š: %sæ£€æŸ¥å¤±è´¥: %v\n", name, err)
			fileAvailable[name] = false
		} else {
			fileAvailable[name] = true
		}
	}

	// 5. æž„å»ºè¾“å‡ºç»“æžœç»“æž„ï¼ˆåˆå§‹åŒ–æ‰€æœ‰è·¯å¾„ï¼‰
	result := &ExportResult{
		StockInfoFile:            filepath.Join(outputDir, "stocks_info.csv"),
		HolidaysFile:             filepath.Join(outputDir, "holidays.csv"),
		BlockMembersConceptFile:  filepath.Join(outputDir, "blocks_concept_member.csv"),
		BlockMembersIndustryFile: filepath.Join(outputDir, "blocks_industry_member.csv"),
		BlockInfoFile:            filepath.Join(outputDir, "blocks_info.csv"),
	}

	// 6. å¯¼å‡ºè‚¡ç¥¨ä¿¡æ¯
	if fileAvailable["è‚¡ç¥¨ä¿¡æ¯æ–‡ä»¶"] {
		stockInfo, err := ReadInfoharborCode(inputFiles["è‚¡ç¥¨ä¿¡æ¯æ–‡ä»¶"])
		if err != nil {
			result.StockInfoFile = ""
		} else if err := writeCSV(result.StockInfoFile, stockInfo); err != nil {
			result.StockInfoFile = ""
		}
	} else {
		result.StockInfoFile = ""
	}

	// 7. å¯¼å‡ºäº¤æ˜“æ—¥åŽ†
	if fileAvailable["å‡æœŸæ—¥åŽ†æ–‡ä»¶"] {
		holidays, err := ReadHolidays(inputFiles["å‡æœŸæ—¥åŽ†æ–‡ä»¶"])
		if err != nil {
			result.HolidaysFile = ""
		} else if err := writeCSV(result.HolidaysFile, holidays); err != nil {
			result.HolidaysFile = ""
		}
	} else {
		result.HolidaysFile = ""
	}

	// 8. å¯¼å‡ºæ¦‚å¿µæ¿å—æˆå‘˜
	if fileAvailable["æ¦‚å¿µæ¿å—æ–‡ä»¶"] {
		gnbkData, err := ReadInfoharborBlock(inputFiles["æ¦‚å¿µæ¿å—æ–‡ä»¶"])
		if err != nil {
			result.BlockMembersConceptFile = ""
		} else if err := writeCSV(result.BlockMembersConceptFile, gnbkData); err != nil {
			result.BlockMembersConceptFile = ""
		}
	} else {
		result.BlockMembersConceptFile = ""
	}

	// 9. å¯¼å‡ºè¡Œä¸šæˆå‘˜
	if fileAvailable["è¡Œä¸šæ•°æ®æ–‡ä»¶"] {
		tdxhyData, err := ReadTDXHY(inputFiles["è¡Œä¸šæ•°æ®æ–‡ä»¶"])
		if err != nil {
			result.BlockMembersIndustryFile = ""
		} else if err := writeCSV(result.BlockMembersIndustryFile, tdxhyData); err != nil {
			result.BlockMembersIndustryFile = ""
		}
	} else {
		result.BlockMembersIndustryFile = ""
	}

	// 10. å¯¼å‡ºæ¿å—ä¿¡æ¯
	if fileAvailable["æ¿å—ä¿¡æ¯æ–‡ä»¶"] {
		blockInfo, err := ReadTDXZS3(inputFiles["æ¿å—ä¿¡æ¯æ–‡ä»¶"])
		if err != nil {
			result.BlockInfoFile = ""
		} else if err := writeCSV(result.BlockInfoFile, blockInfo); err != nil {
			result.BlockInfoFile = ""
		}
	} else {
		result.BlockInfoFile = ""
	}

	return result, nil
}

// writeCSV é€šç”¨CSVå†™å…¥å‡½æ•°
func writeCSV[T any](csvPath string, data []T) error {
	cw, err := utils.NewCSVWriter[T](csvPath)
	if err != nil {
		return err
	}
	defer cw.Close()
	return cw.Write(data)
}

// ReadHolidays è¯»å–å‡æ—¥æ•°æ®æ–‡ä»¶
func ReadHolidays(filePath string) ([]model.Holiday, error) {
	content, err := os.ReadFile(filePath)
	if err != nil {
		return nil, err
	}

	var allHolidays []string
	lines := strings.Split(string(content), "\n")

	for _, line := range lines {
		line = strings.TrimSpace(line)
		if line == "" || !strings.HasPrefix(line, "Y") || !strings.Contains(line, "=") {
			continue
		}

		parts := strings.SplitN(line, "=", 2)
		if len(parts) != 2 {
			continue
		}

		datePart := parts[1]
		items := strings.Split(datePart, ",")

		var cleanItems []string
		for _, item := range items {
			item = strings.TrimSpace(item)
			if item != "" {
				cleanItems = append(cleanItems, item)
			}
		}

		if len(cleanItems) == 0 {
			continue
		}

		year := cleanItems[0]
		dates := cleanItems[1:]

		for _, dateMMDD := range dates {
			if len(dateMMDD) == 4 {
				month := dateMMDD[:2]
				day := dateMMDD[2:]
				fullDate := fmt.Sprintf("%s-%s-%s", year, month, day)
				allHolidays = append(allHolidays, fullDate)
			}
		}
	}

	sort.Strings(allHolidays)

	holidays := make([]model.Holiday, 0, len(allHolidays))
	for _, dateStr := range allHolidays {
		date, err := time.Parse("2006-01-02", dateStr)
		if err != nil {
			fmt.Printf("è­¦å‘Š: è§£æžæ—¥æœŸå¤±è´¥ %s: %v\n", dateStr, err)
			continue
		}
		holidays = append(holidays, model.Holiday{Date: date})
	}

	return holidays, nil
}

// ReadInfoharborCode è¯»å–è‚¡ç¥¨ä»£ç æ–‡ä»¶
func ReadInfoharborCode(filePath string) ([]model.StockInfo, error) {
	file, err := os.Open(filePath)
	if err != nil {
		return nil, err
	}
	defer file.Close()

	decoder := transform.NewReader(file, simplifiedchinese.GBK.NewDecoder())
	scanner := bufio.NewScanner(decoder)

	var stockInfos []model.StockInfo

	for scanner.Scan() {
		line := strings.TrimSpace(scanner.Text())
		if line == "" {
			continue
		}

		parts := strings.Split(line, "|")
		if len(parts) >= 2 {
			code := strings.TrimSpace(parts[0])
			name := strings.TrimSpace(parts[1])
			symbol, ok := utils.GenerateSymbol(code)
			if ok {
				stockInfos = append(stockInfos, model.StockInfo{
					Symbol: symbol,
					Name:   name,
				})
			}
		}
	}

	if err := scanner.Err(); err != nil {
		return nil, err
	}

	return stockInfos, nil
}

// ReadInfoharborBlock è¯»å–æ¦‚å¿µã€é£Žæ ¼ã€æŒ‡æ•°æˆåˆ†è‚¡
func ReadInfoharborBlock(filePath string) ([]model.BlockMember, error) {
	content, err := readGBKFile(filePath)
	if err != nil {
		return nil, err
	}

	blockTypeMap := map[string]string{
		"GN": "gn",
		"FG": "fg",
	}

	var parsedData []struct {
		BlockCode string
		Stocks    []string
	}

	re := regexp.MustCompile(`(?m)^#(GN_|FG_|ZS_)`)
	matches := re.FindAllStringIndex(content, -1)

	var sections []string
	if len(matches) > 0 {
		if matches[0][0] > 0 {
			sections = append(sections, content[:matches[0][0]])
		}

		for i := 0; i < len(matches); i++ {
			start := matches[i][0]
			var end int
			if i+1 < len(matches) {
				end = matches[i+1][0]
			} else {
				end = len(content)
			}
			sections = append(sections, content[start:end])
		}
	}

	for _, section := range sections {
		section = strings.TrimSpace(section)
		if section == "" {
			continue
		}

		if !strings.HasPrefix(section, "#GN_") &&
			!strings.HasPrefix(section, "#FG_") &&
			!strings.HasPrefix(section, "#ZS_") {
			continue
		}

		sectionPrefix := section[1:3]

		if _, ok := blockTypeMap[sectionPrefix]; !ok {
			continue
		}

		lines := strings.Split(section, "\n")
		if len(lines) == 0 {
			continue
		}

		headerLine := lines[0]
		headerParts := strings.Split(headerLine, ",")

		if len(headerParts) < 3 {
			continue
		}

		headerFirst := strings.TrimPrefix(headerParts[0], "#")
		blockCodeParts := strings.SplitN(headerFirst, "_", 2)
		if len(blockCodeParts) < 2 {
			continue
		}
		blockCode := blockCodeParts[1]

		stockLines := lines[1:]
		allCodesStr := strings.Join(stockLines, "")

		var formattedStocks []string
		for _, rawCode := range strings.Split(allCodesStr, ",") {
			code := strings.TrimSpace(rawCode)
			if code == "" || !strings.Contains(code, "#") {
				continue
			}

			parts := strings.Split(code, "#")
			if len(parts) != 2 {
				continue
			}

			prefix := parts[0]
			stockNum := parts[1]

			switch prefix {
			case "0":
				formattedStocks = append(formattedStocks, "sz"+stockNum)
			case "1":
				formattedStocks = append(formattedStocks, "sh"+stockNum)
			case "2":
				formattedStocks = append(formattedStocks, "bj"+stockNum)
			}
		}

		parsedData = append(parsedData, struct {
			BlockCode string
			Stocks    []string
		}{
			BlockCode: blockCode,
			Stocks:    formattedStocks,
		})
	}

	var records []model.BlockMember
	for _, item := range parsedData {
		for _, stockSymbol := range item.Stocks {
			records = append(records, model.BlockMember{
				StockSymbol: stockSymbol,
				BlockCode:   item.BlockCode,
			})
		}
	}

	return records, nil
}

// ReadTDXZS3 è¯»å–æ¿å—åç§°ã€ä»£ç ã€ç¼–ç 
func ReadTDXZS3(filePath string) ([]model.BlockInfo, error) {
	file, err := os.Open(filePath)
	if err != nil {
		return nil, err
	}
	defer file.Close()

	decoder := transform.NewReader(file, simplifiedchinese.GBK.NewDecoder())
	reader := csv.NewReader(decoder)
	reader.Comma = '|'
	reader.FieldsPerRecord = -1

	var blockInfos []model.BlockInfo

	for {
		record, err := reader.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			return nil, err
		}

		if len(record) < 6 {
			continue
		}

		blkName := record[0]
		blkCode := record[1]
		blkType := record[2]
		blkLabel := strings.TrimSpace(record[5])

		blockSymbol := "sh" + blkCode

		var parentCode string
		blockLevel := 1

		labelLen := len(blkLabel)

		// è§„åˆ™ A: Type 12 (é€šè¾¾ä¿¡ç ”ç©¶è¡Œä¸š)
		if blkType == "12" {
			switch labelLen {
			case 5:
				parent := blkLabel[:3]
				parentCode = parent
				blockLevel = 2
			case 7:
				parent := blkLabel[:5]
				parentCode = parent
				blockLevel = 3
			}
		}

		// è§„åˆ™ B: Type 2 (é€šè¾¾ä¿¡æ™®é€šè¡Œä¸š)
		if blkType == "2" {
			if labelLen == 7 {
				parent := blkLabel[:5]
				parentCode = parent
				blockLevel = 2
			}
		}

		// ç±»åž‹æ˜ å°„
		typeMapping := map[string]string{
			"2":  "tdx_general",
			"3":  "region",
			"4":  "concept",
			"5":  "style",
			"12": "tdx_research",
		}

		blockType := blkType
		if mappedType, ok := typeMapping[blkType]; ok {
			blockType = mappedType
		}

		blockInfos = append(blockInfos, model.BlockInfo{
			BlockType:   blockType,
			BlockName:   blkName,
			BlockSymbol: blockSymbol,
			BlockCode:   blkLabel,
			ParentCode:  parentCode,
			BlockLevel:  blockLevel,
		})
	}

	return blockInfos, nil
}

// ReadTDXHY è¯»å–é€šè¾¾ä¿¡ç ”ç©¶å’Œæ™®é€šè¡Œä¸šæˆåˆ†è‚¡
func ReadTDXHY(filePath string) ([]model.BlockMember, error) {
	file, err := os.Open(filePath)
	if err != nil {
		return nil, err
	}
	defer file.Close()

	reader := csv.NewReader(file)
	reader.Comma = '|'
	reader.FieldsPerRecord = -1

	var members []model.BlockMember

	prefixMap := map[string]string{
		"0": "sz",
		"1": "sh",
		"2": "bj",
	}

	for {
		record, err := reader.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			return nil, err
		}

		if len(record) < 6 {
			continue
		}

		exchange := record[0]
		code := record[1]
		tdxhyT := record[2]
		tdxhyX := record[5]

		// è¿‡æ»¤æ¡ä»¶
		if exchange == "0" && strings.HasPrefix(code, "20") {
			continue
		}

		prefix, ok := prefixMap[exchange]
		if !ok {
			continue
		}

		stockSymbol := prefix + code

		// æ·»åŠ  tdxhy_T
		if tdxhyT != "" {
			members = append(members, model.BlockMember{
				StockSymbol: stockSymbol,
				BlockCode:   tdxhyT,
			})
		}

		// æ·»åŠ  tdxhy_X
		if tdxhyX != "" {
			members = append(members, model.BlockMember{
				StockSymbol: stockSymbol,
				BlockCode:   tdxhyX,
			})
		}
	}

	return members, nil
}

// expandPath å±•å¼€è·¯å¾„ä¸­çš„ ~ ç¬¦å·
func expandPath(path string) string {
	if strings.HasPrefix(path, "~/") {
		home, err := os.UserHomeDir()
		if err != nil {
			return path
		}
		return filepath.Join(home, path[2:])
	}
	return path
}

// readGBKFile è¯»å–GBKç¼–ç çš„æ–‡ä»¶
func readGBKFile(filePath string) (string, error) {
	file, err := os.Open(filePath)
	if err != nil {
		return "", err
	}
	defer file.Close()

	decoder := transform.NewReader(file, simplifiedchinese.GBK.NewDecoder())
	content, err := io.ReadAll(decoder)
	if err != nil {
		return "", err
	}

	return string(content), nil
}
